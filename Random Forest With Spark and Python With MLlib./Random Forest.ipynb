{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Methods Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #1: Understand the Problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dog food company first mixes up a batch of preservative that contains 4 different preservative chemicals (A,B,C,D) and then is completed with a \"filler\" chemical. The food scientists belive one of the A,B,C, or D preservatives is causing the problem, but need your help to figure out which one!\n",
    "Use Machine Learning with RF to find out which parameter had the most predicitive power, thus finding out which chemical causes the early spoiling! So create a model and then find out how you can decide which chemical is the problem!\n",
    "\n",
    "* Pres_A : Percentage of preservative A in the mix\n",
    "* Pres_B : Percentage of preservative B in the mix\n",
    "* Pres_C : Percentage of preservative C in the mix\n",
    "* Pres_D : Percentage of preservative D in the mix\n",
    "* Spoiled: Label indicating whether or not the dog food batch was spoiled.\n",
    "\n",
    "##### WE WANT TO UNDERSTAND THE FUNDAMENTAL REALATIONSHIP BTW EACH FEATURE COLUMN AND THE LABEL ITSELF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #2: Import the Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree methods Example\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('dogfood').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK #3: READ THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = spark.read.csv('dog_food.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(A=4, B=2, C=12.0, D=3, Spoiled=1.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|                 A|                 B|                 C|                 D|            Spoiled|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|               490|               490|               490|               490|                490|\n",
      "|   mean|  5.53469387755102| 5.504081632653061| 9.126530612244897| 5.579591836734694| 0.2857142857142857|\n",
      "| stddev|2.9515204234399057|2.8537966089662063|2.0555451971054275|2.8548369309982857|0.45221563164613465|\n",
      "|    min|                 1|                 1|               5.0|                 1|                0.0|\n",
      "|    max|                10|                10|              14.0|                10|                1.0|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK #4:Spark Formatting of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VectorAssembler and Vectors\n",
    "# A few things we need to do before Spark can accept the data!\n",
    "# It needs to be in the form of two columns\n",
    "# (\"label\",\"features\")\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'Spoiled']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['A', 'B', 'C', 'D'],outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK #5:The Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier,DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = DecisionTreeClassifier(labelCol='Spoiled',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=DenseVector([4.0, 2.0, 12.0, 3.0]), Spoiled=1.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = output.select('features','Spoiled')\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|           features|Spoiled|\n",
      "+-------------------+-------+\n",
      "| [4.0,2.0,12.0,3.0]|    1.0|\n",
      "| [5.0,6.0,12.0,7.0]|    1.0|\n",
      "| [6.0,2.0,13.0,6.0]|    1.0|\n",
      "| [4.0,2.0,12.0,1.0]|    1.0|\n",
      "| [4.0,2.0,12.0,3.0]|    1.0|\n",
      "|[10.0,3.0,13.0,9.0]|    1.0|\n",
      "| [8.0,5.0,14.0,5.0]|    1.0|\n",
      "| [5.0,8.0,12.0,8.0]|    1.0|\n",
      "| [6.0,5.0,12.0,9.0]|    1.0|\n",
      "| [3.0,3.0,12.0,1.0]|    1.0|\n",
      "| [9.0,8.0,11.0,3.0]|    1.0|\n",
      "|[1.0,10.0,12.0,3.0]|    1.0|\n",
      "|[1.0,5.0,13.0,10.0]|    1.0|\n",
      "|[2.0,10.0,12.0,6.0]|    1.0|\n",
      "|[1.0,10.0,11.0,4.0]|    1.0|\n",
      "| [5.0,3.0,12.0,2.0]|    1.0|\n",
      "| [4.0,9.0,11.0,8.0]|    1.0|\n",
      "| [5.0,1.0,11.0,1.0]|    1.0|\n",
      "|[4.0,9.0,12.0,10.0]|    1.0|\n",
      "| [5.0,8.0,10.0,9.0]|    1.0|\n",
      "+-------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = rfc.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([4.0, 2.0, 12.0, 3.0]), Spoiled=1.0)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK #6:Apply Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {1: 0.0019, 2: 0.9832, 3: 0.0149})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree method classifier had a featurei,portances attribute available. \n",
    "# After Creating a model and fit it all data then check which feature causing the spoil.\n",
    "\n",
    "rfc_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature at index 2 (Chemical C) is by far the most important feature, meaning it is causing the early spoilage! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
